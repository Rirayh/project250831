08/30 11:08:41 - OpenCompass - INFO - Task [pard-qwen2.5-7b/demo_gsm8k]
08/30 11:08:46 - OpenCompass - INFO - Initializing PardDreamEngine...
08/30 11:08:46 - OpenCompass - INFO - Loading target model: Qwen/Qwen2.5-7B-Instruct
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.46it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  5.65it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  5.43it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.56it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.54it/s]
08/30 11:08:50 - OpenCompass - INFO - Loading draft model: Dream-org/Dream-v0-Instruct-7B
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  4.55it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  5.09it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  5.30it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.51it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.33it/s]
/net/scratch2/zhaorun/zichen/junlong/conda_envs/fdllm/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/net/scratch2/zhaorun/zichen/junlong/conda_envs/fdllm/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
08/30 11:08:55 - OpenCompass - WARNING - eos_token_id not found in meta_template, using tokenizer's default: 151645
08/30 11:08:55 - OpenCompass - INFO - PardDreamEngine initialized successfully.
Traceback (most recent call last):
  File "/net/scratch2/zhaorun/zichen/junlong/projects/pard_eval_on_opencompass/opencompass/tasks/openicl_infer.py", line 161, in <module>
    inferencer.run()
  File "/net/scratch2/zhaorun/zichen/junlong/projects/pard_eval_on_opencompass/opencompass/tasks/openicl_infer.py", line 73, in run
    self.model = build_model_from_cfg(model_cfg)
  File "/net/scratch2/zhaorun/zichen/junlong/projects/pard_eval_on_opencompass/opencompass/utils/build.py", line 24, in build_model_from_cfg
    return MODELS.build(model_cfg)
  File "/net/scratch2/zhaorun/zichen/junlong/conda_envs/fdllm/lib/python3.10/site-packages/mmengine/registry/registry.py", line 570, in build
    return self.build_func(cfg, *args, **kwargs, registry=self)
  File "/net/scratch2/zhaorun/zichen/junlong/conda_envs/fdllm/lib/python3.10/site-packages/mmengine/registry/build_functions.py", line 121, in build_from_cfg
    obj = obj_cls(**args)  # type: ignore
  File "/net/scratch2/zhaorun/zichen/junlong/projects/pard_eval_on_opencompass/opencompass/models/pard_dream_model.py", line 223, in __init__
    self.template_parser = self.engine.target_tokenizer.apply_chat_template(tokenize=False,add_generation_prompt=True)# self._get_meta_template(meta_template)
TypeError: PreTrainedTokenizerBase.apply_chat_template() missing 1 required positional argument: 'conversation'
